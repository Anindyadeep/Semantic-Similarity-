{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6a33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "import random\n",
    "import warnings  \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "from tqdm.notebook import tqdm \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd214625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af220260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/anindya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anindya/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/anindya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6ac489",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    '../Data/train.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb855258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility functions to clean the text \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def decontract(text):\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text\n",
    "\n",
    "def process_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    text = re.sub(r'$\\w*', '', text)\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = str(re.sub(\"\\S*\\d\\S*\", \"\", text).strip()) \n",
    "    text=decontract(text)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    texts_clean = []\n",
    "    for word in tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation+'...'):  # remove punctuation\n",
    "            # \n",
    "            stem_word = lemmatizer.lemmatize(word,\"v\")  # Lemmatizing word\n",
    "            texts_clean.append(stem_word)\n",
    "\n",
    "    return \" \".join(texts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb2d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda text: process_text(text))\n",
    "data['reason'] = data['reason'].apply(lambda reason: process_text(reason))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1825d",
   "metadata": {},
   "source": [
    "### Dividing the data into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ed0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = data.sample(1000, random_state=143)\n",
    "sample1_index = sample1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37516e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = len(data) - 1000\n",
    "sample2 = data[~data.index.isin(sample1_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7f51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1, sample2 = sample1.reset_index(drop=True), sample2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a47c5a",
   "metadata": {},
   "source": [
    "**Negative sampling for Sample1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3628ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 18:35:15.144452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 18:35:15.348193: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-30 18:35:16.040137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-30 18:35:16.040286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-30 18:35:16.040291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e3f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6d9e0954c9406f90a1cbc424e60e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c68b91236549a19a3469f86c63ac45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', \n",
    "    action=\"substitute\",aug_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d51cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text(text):\n",
    "    return aug.augment(text, n=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f515fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f73f6841944cc68e1783e7d5ebf967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c5b06f6e0d4001aa21a437a845a449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample1['text'] = sample1['text'].progress_apply(lambda text: augment_text(text))\n",
    "sample1['reason'] = sample1['reason'].progress_apply(lambda text: augment_text(text))\n",
    "sample1['label'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8570af",
   "metadata": {},
   "source": [
    "**Negative sampling for Sample2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9def7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline  \n",
    "\n",
    "generator = pipeline(\n",
    "    'text-generation', model='gpt2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3f6a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_samples = []\n",
    "sampled_reasons = sample2['reason'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb522935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_prompt(prompt):\n",
    "    generated_reason = generator(\n",
    "        prompt, \n",
    "        max_length=len(prompt), pad_token_id=50256, num_return_sequences=1\n",
    "    )[0]['generated_text'][len(prompt):]\n",
    "    return generated_reason.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dd363f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc77323907d4d48809da4f6b2d5cf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_texts = []\n",
    "for prompt in tqdm(sampled_reasons, total=len(sampled_reasons)):\n",
    "    generated_texts.append(\n",
    "        generate_text_from_prompt(prompt)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "235d8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca45c19afc4805b315151db2174994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_reasons=[]\n",
    "sampled_texts = sample2['text'].tolist()\n",
    "\n",
    "for prompt in tqdm(sampled_texts, total=len(sampled_texts)):\n",
    "    generated_reasons.append(\n",
    "        generate_text_from_prompt(prompt)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f6e246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2['generated_text'] = generated_texts\n",
    "sample2['generated_reason'] = generated_reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea05a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69c4ef11538461e8979c929a32db4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cc55ff38114828bf688dd80ac90bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample2['generated_text'] = sample2['generated_text'].progress_apply(lambda text: process_text(text))\n",
    "sample2['generated_reason'] = sample2['generated_reason'].progress_apply(lambda reason: process_text(reason))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bd726a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5807f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = sample2[['generated_text', 'generated_reason', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e04f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reason</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timewe meet share class time</td>\n",
       "      <td>think case bite easier find</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>magazine addition also additional support offl...</td>\n",
       "      <td>installationproudly make easy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stability make search base search significantl...</td>\n",
       "      <td>app support video audio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low quality higher quality positive</td>\n",
       "      <td>think seem really crappy video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>sign password mail</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                       timewe meet share class time   \n",
       "1  magazine addition also additional support offl...   \n",
       "2  stability make search base search significantl...   \n",
       "3                low quality higher quality positive   \n",
       "4                                                      \n",
       "\n",
       "                           reason  label  \n",
       "0     think case bite easier find      0  \n",
       "1   installationproudly make easy      0  \n",
       "2         app support video audio      0  \n",
       "3  think seem really crappy video      0  \n",
       "4              sign password mail      0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2.columns = ['text', 'reason', 'label']\n",
    "sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02fd5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "mkdir samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d48bcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1.to_csv('samples/sample1.csv')\n",
    "sample2.to_csv('samples/sample2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6118e",
   "metadata": {},
   "source": [
    "### Approach 3 500 + 500 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a39e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_aug = naw.AntonymAug('wordnet',aug_max=3)\n",
    "syn_aug = naw.SynonymAug('wordnet', aug_max=3)\n",
    "del_aug = naw.RandomWordAug(aug_max=3, action='delete')\n",
    "sub_aug = naw.RandomWordAug(aug_max=3, action='substitute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0416b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text_oppo(text):\n",
    "    return aug2.augment(text, n=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6de05a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1000 = data.sample(1000, random_state=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae97c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_aug(df):\n",
    "    df1 = df.iloc[:250, :]\n",
    "    df2 = df.iloc[250:500, :]\n",
    "    df3 = df.iloc[500:750, :]\n",
    "    df4 = df.iloc[750:, :]\n",
    "    \n",
    "    df1['text'] = df1['text'].progress_apply(lambda x : opp_aug.augment(x, n=1)[0])\n",
    "    df1['reason'] = df1['reason'].progress_apply(lambda x : syn_aug.augment(x, n=1)[0])\n",
    "\n",
    "    df2['text'] = df2['text'].progress_apply(lambda x : del_aug.augment(x, n=1)[0])\n",
    "    df2['reason'] = df2['reason'].progress_apply(lambda x : sub_aug.augment(x, n=1)[0])\n",
    "\n",
    "    df3['text'] = df3['text'].progress_apply(lambda x : opp_aug.augment(x, n=1)[0])\n",
    "    df3['reason'] = df3['reason'].progress_apply(lambda x : del_aug.augment(x, n=1)[0])\n",
    "\n",
    "    df4['text'] = df4['text'].progress_apply(lambda x : sub_aug.augment(x, n=1)[0])\n",
    "    df4['reason'] = df4['reason'].progress_apply(lambda x : syn_aug.augment(x, n=1)[0])\n",
    "    \n",
    "    text2 = df2['text'].tolist()\n",
    "    text3 = df4['text'].tolist()\n",
    "    \n",
    "    df2['text'] = text3\n",
    "    df3['text'] = text2\n",
    "    \n",
    "    df = pd.concat([df1, df2, df3, df4], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f675b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad1c5d77edc44a69112e4700a928ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/anindya/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249018a648c148e6a3536f541b78e84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample1000['text'] = sample1000['text'].progress_apply(lambda text: augment_text_oppo(text))\n",
    "sample1000['reason'] = sample1000['reason'].progress_apply(lambda text: augment_text_oppo(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "477679d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73755a192c5a40098ef547eff8035a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9769f909624c789f676fa64548249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552eef6c40d144069b6699aea1510f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff7eaf2bc224e96a6be58c1d1514871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296bfaacac4b412ba9ded74e4eb67d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e667bc8d6004c8caacafedccb31ac1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b807970049e431cbcd6559b2479fce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09662488809945908778511fb5d49f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample1000_aug = random_aug(sample1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a2c2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1000_aug['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00e9bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1000.to_csv('samples/sample1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b22cc",
   "metadata": {},
   "source": [
    "### Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
